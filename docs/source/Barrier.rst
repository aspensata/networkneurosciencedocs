Understanding Thought Without Action: A Surmountable Barrier
============================================================

We have established that the brain performs operations at various scales, and that these operations are poorly understood. There is some kind of internal, regular structure or code between neurons that occurs as a series of stepwise updating rules (Ebitz & Hayden, 2021). This code is not consistent everywhere in the brain, and while it is well understood for some parts of the brain, like the visual cortex, it is poorly understood for other brain systems such as those that deal with inner thought, emotion, or preference. Why? This is for the aforementioned reason that without common anchors to the real world outcomes of a thought, it is difficult to tell what is actually occurring. This may sound like a paradox: if we understand thought through the actions it produces, and much inner thought and experience produces no action, then how can it be understood at all? 

To this end, psychologists have long understood the importance of self-report. In the late 1800s, Edward Tichener, one of the fathers of modern psychology, wrote, “The state of consciousness which is to be the matter of psychology ... can become an object of immediate knowledge only by way of introspection or self-awareness” (Schwitzgebel) Until neuroimaging technologies revealed a correspondence between thought and action, introspection was the only tool available to psychologists to intuit the inner workings of the brain. This had important drawbacks. Even the “introspective engine” of the brain operates at a specific scale. This ability to consciously perceive our inner states is limited: we are not aware of every summation, integration, and action impulse in our own brains. Introspective ability is itself a product of the neural code. Consequently, if disease processes involve variations in the neural code beyond the threshold of introspection, they will at best be visible by their downstream effects and not at the level of the errors themselves. In the last five years, we have started to develop anchor points for the actual computations neural networks perform. This lets us determine a more direct correspondence between brain activity and the subject of self-reported introspection.
